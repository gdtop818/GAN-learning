{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adward\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import vgg19\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "import tfutil as t\n",
    "\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "\n",
    "class SRGAN:\n",
    "\n",
    "    def __init__(self, s, batch_size=16, height=384, width=384, channel=3,\n",
    "                 sample_num=1 * 1, sample_size=1,\n",
    "                 df_dim=64, gf_dim=64, lr=1e-4, use_vgg19=True):\n",
    "\n",
    "        \"\"\" Super-Resolution GAN Class\n",
    "        # General Settings\n",
    "        :param s: TF Session\n",
    "        :param batch_size: training batch size, default 16\n",
    "        :param height: input image height, default 384\n",
    "        :param width: input image width, default 384\n",
    "        :param channel: input image channel, default 3 (RGB)\n",
    "        - in case of DIV2K-HR, image size is 384x384x3(HWC).\n",
    "\n",
    "        # Output Settings\n",
    "        :param sample_num: the number of output images, default 1\n",
    "        :param sample_size: sample image size, default 1\n",
    "\n",
    "        # For CNN model\n",
    "        :param df_dim: discriminator filter, default 64\n",
    "        :param gf_dim: generator filter, default 64\n",
    "\n",
    "        # Training Option\n",
    "        :param lr: learning rate, default 1e-4\n",
    "        :param use_vgg19: using pre-trained vgg19 bottle-neck features, default False\n",
    "        \"\"\"\n",
    "\n",
    "        self.s = s\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channel = channel\n",
    "\n",
    "        self.lr_image_shape = [None, self.height // 4, self.width // 4, self.channel]\n",
    "        self.hr_image_shape = [None, self.height, self.width, self.channel]\n",
    "\n",
    "        self.vgg_image_shape = [224, 224, 3]\n",
    "\n",
    "        self.sample_num = sample_num\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self.df_dim = df_dim\n",
    "        self.gf_dim = gf_dim\n",
    "\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "\n",
    "        self.lr_decay_rate = 1e-1\n",
    "        self.lr_low_boundary = 1e-5\n",
    "        self.lr_update_step = 1e5\n",
    "        self.lr_update_epoch = 1000\n",
    "\n",
    "        self.vgg_mean = [103.939, 116.779, 123.68]\n",
    "\n",
    "        # pre-defined\n",
    "        self.d_real = 0.\n",
    "        self.d_fake = 0.\n",
    "        self.d_loss = 0.\n",
    "        self.g_adv_loss = 0.\n",
    "        self.g_cnt_loss = 0.\n",
    "        self.g_loss = 0.\n",
    "        self.psnr = 0.\n",
    "\n",
    "        self.use_vgg19 = use_vgg19\n",
    "        self.vgg19 = None\n",
    "\n",
    "        self.g = None\n",
    "\n",
    "        self.adv_scaling = 1e-3\n",
    "        self.cnt_scaling = 1. / 12.75  # 6e-3\n",
    "\n",
    "        self.d_op = None\n",
    "        self.g_op = None\n",
    "        self.g_init_op = None\n",
    "\n",
    "        self.merged = None\n",
    "        self.writer = None\n",
    "        self.saver = None\n",
    "\n",
    "        # Placeholders\n",
    "        self.x_hr = tf.placeholder(tf.float32, shape=self.hr_image_shape, name=\"x-image-hr\")  # (-1, 384, 384, 3)\n",
    "        self.x_lr = tf.placeholder(tf.float32, shape=self.lr_image_shape, name=\"x-image-lr\")  # (-1, 96, 96, 3)\n",
    "\n",
    "        self.lr = tf.placeholder(tf.float32, name='lr')\n",
    "\n",
    "        self.build_srgan()  # build SRGAN model\n",
    "\n",
    "    def discriminator(self, x, reuse=None):\n",
    "        \"\"\"\n",
    "        # Following a network architecture referred in the paper\n",
    "        :param x: Input images (-1, 384, 384, 3)\n",
    "        :param reuse: re-usability\n",
    "        :return: HR (High Resolution) or SR (Super Resolution) images\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "            x = t.conv2d(x, self.df_dim, 3, 1, name='n64s1-1')\n",
    "            x = tf.nn.leaky_relu(x)\n",
    "\n",
    "            strides = [2, 1]\n",
    "            filters = [1, 2, 2, 4, 4, 8, 8]\n",
    "\n",
    "            for i, f in enumerate(filters):\n",
    "                x = t.conv2d(x, f=f, k=3, s=strides[i % 2], name='n%ds%d-%d' % (f, strides[i % 2], i + 1))\n",
    "                x = t.batch_norm(x, name='n%d-bn-%d' % (f, i + 1))\n",
    "                x = tf.nn.leaky_relu(x)\n",
    "\n",
    "            x = tf.layers.flatten(x)  # (-1, 96 * 96 * 64)\n",
    "\n",
    "            x = t.dense(x, 1024, name='disc-fc-1')\n",
    "            x = tf.nn.leaky_relu(x)\n",
    "\n",
    "            x = t.dense(x, 1, name='disc-fc-2')\n",
    "            # x = tf.nn.sigmoid(x)\n",
    "            return x\n",
    "\n",
    "    def generator(self, x, reuse=None, is_train=True):\n",
    "        \"\"\"\n",
    "        :param x: LR (Low Resolution) images, (-1, 96, 96, 3)\n",
    "        :param reuse: scope re-usability\n",
    "        :param is_train: is trainable, default True\n",
    "        :return: SR (Super Resolution) images, (-1, 384, 384, 3)\n",
    "        \"\"\"\n",
    "\n",
    "        with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "            def residual_block(x, f, name=\"\", _is_train=True):\n",
    "                with tf.variable_scope(name):\n",
    "                    shortcut = tf.identity(x, name='n64s1-shortcut')\n",
    "\n",
    "                    x = t.conv2d(x, f, 3, 1, name=\"n64s1-1\")\n",
    "                    x = t.batch_norm(x, is_train=_is_train, name=\"n64s1-bn-1\")\n",
    "                    x = t.prelu(x, reuse=reuse, name='n64s1-prelu-1')\n",
    "                    x = t.conv2d(x, f, 3, 1, name=\"n64s1-2\")\n",
    "                    x = t.batch_norm(x, is_train=_is_train, name=\"n64s1-bn-2\")\n",
    "                    x = tf.add(x, shortcut)\n",
    "\n",
    "                    return x\n",
    "\n",
    "            x = t.conv2d(x, self.gf_dim, 9, 1, name='n64s1-1')\n",
    "            x = t.prelu(x, name='n64s1-prelu-1')\n",
    "\n",
    "            skip_conn = tf.identity(x, name='skip_connection')\n",
    "\n",
    "            # B residual blocks\n",
    "            for i in range(1, 17):  # (1, 9)\n",
    "                x = residual_block(x, self.gf_dim, name='b-residual_block_%d' % i, _is_train=is_train)\n",
    "\n",
    "            x = t.conv2d(x, self.gf_dim, 3, 1, name='n64s1-3')\n",
    "            x = t.batch_norm(x, is_train=is_train, name='n64s1-bn-3')\n",
    "\n",
    "            x = tf.add(x, skip_conn)\n",
    "\n",
    "            # sub-pixel conv2d blocks\n",
    "            for i in range(1, 3):\n",
    "                x = t.conv2d(x, self.gf_dim * 4, 3, 1, name='n256s1-%d' % (i + 2))\n",
    "                x = t.sub_pixel_conv2d(x, f=None, s=2)\n",
    "                x = t.prelu(x, name='n256s1-prelu-%d' % i)\n",
    "\n",
    "            x = t.conv2d(x, self.channel, 9, 1, name='n3s1')  # (-1, 384, 384, 3)\n",
    "            x = tf.nn.tanh(x)\n",
    "            return x\n",
    "\n",
    "    def build_vgg19(self, x, reuse=None):\n",
    "        with tf.variable_scope(\"vgg19\", reuse=reuse):\n",
    "            # image re-scaling\n",
    "            x = tf.cast((x + 1) / 2, dtype=tf.float32)  # [-1, 1] to [0, 1]\n",
    "            x = tf.cast(x * 255., dtype=tf.float32)     # [0, 1]  to [0, 255]\n",
    "\n",
    "            r, g, b = tf.split(x, 3, 3)\n",
    "            bgr = tf.concat([b - self.vgg_mean[0],\n",
    "                             g - self.vgg_mean[1],\n",
    "                             r - self.vgg_mean[2]], axis=3)\n",
    "\n",
    "            self.vgg19 = vgg19.VGG19(bgr)\n",
    "\n",
    "            net = self.vgg19.vgg19_net['conv5_4']\n",
    "\n",
    "            return net  # last layer\n",
    "\n",
    "    def build_srgan(self):\n",
    "        # Generator\n",
    "        self.g = self.generator(self.x_lr)\n",
    "\n",
    "        # Discriminator\n",
    "        d_real = self.discriminator(self.x_hr)\n",
    "        d_fake = self.discriminator(self.g, reuse=True)\n",
    "\n",
    "        # Losses\n",
    "        # d_real_loss = -tf.reduce_mean(t.safe_log(d_real))\n",
    "        # d_fake_loss = -tf.reduce_mean(t.safe_log(1. - d_fake))\n",
    "        d_real_loss = t.sce_loss(d_real, tf.ones_like(d_real))\n",
    "        d_fake_loss = t.sce_loss(d_fake, tf.zeros_like(d_fake))\n",
    "        self.d_loss = d_real_loss + d_fake_loss\n",
    "\n",
    "        if self.use_vgg19:\n",
    "            x_vgg_real = tf.image.resize_images(self.x_hr, size=self.vgg_image_shape[:2], align_corners=False)\n",
    "            x_vgg_fake = tf.image.resize_images(self.g, size=self.vgg_image_shape[:2], align_corners=False)\n",
    "\n",
    "            vgg_bottle_real = self.build_vgg19(x_vgg_real)\n",
    "            vgg_bottle_fake = self.build_vgg19(x_vgg_fake, reuse=True)\n",
    "\n",
    "            self.g_cnt_loss = self.cnt_scaling * t.mse_loss(vgg_bottle_fake, vgg_bottle_real, self.batch_size,\n",
    "                                                            is_mean=True)\n",
    "        else:\n",
    "            self.g_cnt_loss = t.mse_loss(self.g, self.x_hr, self.batch_size, is_mean=True)\n",
    "\n",
    "        # self.g_adv_loss = self.adv_scaling * tf.reduce_mean(-1. * t.safe_log(d_fake))\n",
    "        self.g_adv_loss = self.adv_scaling * t.sce_loss(d_fake, tf.ones_like(d_fake))\n",
    "        self.g_loss = self.g_adv_loss + self.g_cnt_loss\n",
    "\n",
    "        def inverse_transform(img):\n",
    "            return (img + 1.) * 127.5\n",
    "\n",
    "        # calculate PSNR\n",
    "        g, x_hr = inverse_transform(self.g), inverse_transform(self.x_hr)\n",
    "        self.psnr = t.psnr_loss(g, x_hr, self.batch_size)\n",
    "\n",
    "        # Summary\n",
    "        tf.summary.scalar(\"loss/d_real_loss\", d_real_loss)\n",
    "        tf.summary.scalar(\"loss/d_fake_loss\", d_fake_loss)\n",
    "        tf.summary.scalar(\"loss/d_loss\", self.d_loss)\n",
    "        tf.summary.scalar(\"loss/g_cnt_loss\", self.g_cnt_loss)\n",
    "        tf.summary.scalar(\"loss/g_adv_loss\", self.g_adv_loss)\n",
    "        tf.summary.scalar(\"loss/g_loss\", self.g_loss)\n",
    "        tf.summary.scalar(\"misc/psnr\", self.psnr)\n",
    "        tf.summary.scalar(\"misc/lr\", self.lr)\n",
    "\n",
    "        # Optimizer\n",
    "        t_vars = tf.trainable_variables()\n",
    "        d_params = [v for v in t_vars if v.name.startswith('d')]\n",
    "        g_params = [v for v in t_vars if v.name.startswith('g')]\n",
    "\n",
    "        self.d_op = tf.train.AdamOptimizer(learning_rate=self.lr,\n",
    "                                           beta1=self.beta1, beta2=self.beta2).minimize(loss=self.d_loss,\n",
    "                                                                                        var_list=d_params)\n",
    "        self.g_op = tf.train.AdamOptimizer(learning_rate=self.lr,\n",
    "                                           beta1=self.beta1, beta2=self.beta2).minimize(loss=self.g_loss,\n",
    "                                                                                        var_list=g_params)\n",
    "\n",
    "        # pre-train\n",
    "        self.g_init_op = tf.train.AdamOptimizer(learning_rate=self.lr,\n",
    "                                                beta1=self.beta1, beta2=self.beta2).minimize(loss=self.g_cnt_loss,\n",
    "                                                                                             var_list=g_params)\n",
    "\n",
    "        # Merge summary\n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "        # Model saver\n",
    "        self.saver = tf.train.Saver(max_to_keep=2)\n",
    "        self.writer = tf.summary.FileWriter('./model/', self.s.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "[-] Path(/home/zero/hdd/DataSet/DIV2K/DIV2K-hr.h5) does not exist :(",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\GAN_learning\\GAN-learning\\chap6\\datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, size, name, use_save, save_file_name, buffer_size, n_threads, use_image_scaling, image_scale, img_save_method, debug)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-70e891843948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-70e891843948>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     ds = DataSet(ds_hr_path=\"/home/zero/hdd/DataSet/DIV2K/DIV2K-hr.h5\",\n\u001b[0;32m     46\u001b[0m                  \u001b[0mds_lr_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"/home/zero/hdd/DataSet/DIV2K/DIV2K-lr.h5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                  use_img_scale=True)\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mhr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhr_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_images\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GAN_learning\\GAN-learning\\chap6\\datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, hr_height, hr_width, lr_height, lr_width, channel, use_split, split_rate, random_state, n_threads, ds_path, ds_name, use_img_scale, ds_hr_path, ds_lr_path, use_save, save_type, save_file_name)\u001b[0m\n\u001b[0;32m    851\u001b[0m                                        \u001b[0muse_image_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_img_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m                                        \u001b[0mimage_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'-1,1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m                                        img_save_method=cv2.INTER_LINEAR).raw_data  # numpy arrays\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         self.lr_images = DataSetLoader(path=self.ds_lr_path,\n",
      "\u001b[1;32m~\\Desktop\\GAN_learning\\GAN-learning\\chap6\\datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, size, name, use_save, save_file_name, buffer_size, n_threads, use_image_scaling, image_scale, img_save_method, debug)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[-] Path(%s) does not exist :(\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: [-] Path(/home/zero/hdd/DataSet/DIV2K/DIV2K-hr.h5) does not exist :("
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('../')\n",
    "import image_utils as iu\n",
    "from datasets import Div2KDataSet as DataSet\n",
    "\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "\n",
    "results = {\n",
    "    'output': './gen_img/',\n",
    "    'model': './model/SRGAN-model.ckpt'\n",
    "}\n",
    "\n",
    "train_step = {\n",
    "    'batch_size': 16,\n",
    "    'init_epochs': 100,\n",
    "    'train_epochs': 1501,\n",
    "    'global_step': 200001,\n",
    "    'logging_interval': 100,\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()  # Clocking start\n",
    "\n",
    "    # Div2K - Track 1: Bicubic downscaling - x4 DataSet load\n",
    "    \"\"\"\n",
    "    ds = DataSet(ds_path=\"/home/zero/hdd/DataSet/DIV2K/\",\n",
    "                 ds_name=\"X4\",\n",
    "                 use_save=True,\n",
    "                 save_type=\"to_h5\",\n",
    "                 save_file_name=\"/home/zero/hdd/DataSet/DIV2K/DIV2K\",\n",
    "                 use_img_scale=True)\n",
    "    \"\"\"\n",
    "    ds = DataSet(ds_hr_path=\"/home/zero/hdd/DataSet/DIV2K/DIV2K-hr.h5\",\n",
    "                 ds_lr_path=\"/home/zero/hdd/DataSet/DIV2K/DIV2K-lr.h5\",\n",
    "                 use_img_scale=True)\n",
    "\n",
    "    hr, lr = ds.hr_images, ds.lr_images\n",
    "\n",
    "    print(\"[+] Loaded HR image \", hr.shape)\n",
    "    print(\"[+] Loaded LR image \", lr.shape)\n",
    "\n",
    "    # GPU configure\n",
    "    gpu_config = tf.GPUOptions(allow_growth=True)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, gpu_options=gpu_config)\n",
    "\n",
    "    with tf.Session(config=config) as s:\n",
    "        with tf.device(\"/gpu:1\"):  # Change\n",
    "            # SRGAN Model\n",
    "            model = SRGAN(s, batch_size=train_step['batch_size'],\n",
    "                                use_vgg19=False)\n",
    "\n",
    "        # Initializing\n",
    "        s.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Load model & Graph & Weights\n",
    "        ckpt = tf.train.get_checkpoint_state('./model/')\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            # Restores from checkpoint\n",
    "            model.saver.restore(s, ckpt.model_checkpoint_path)\n",
    "\n",
    "            global_step = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "            print(\"[+] global step : %d\" % global_step, \" successfully loaded\")\n",
    "        else:\n",
    "            global_step = 0\n",
    "            print('[-] No checkpoint file found')\n",
    "\n",
    "        start_epoch = global_step // (ds.n_images // train_step['batch_size'])\n",
    "\n",
    "        rnd = np.random.randint(0, ds.n_images)\n",
    "        sample_x_hr, sample_x_lr = hr[rnd], lr[rnd]\n",
    "\n",
    "        sample_x_hr, sample_x_lr = \\\n",
    "            np.reshape(sample_x_hr, [1] + model.hr_image_shape[1:]), \\\n",
    "            np.reshape(sample_x_lr, [1] + model.lr_image_shape[1:])\n",
    "\n",
    "        # Export real image\n",
    "        # valid_image_height = model.sample_size\n",
    "        # valid_image_width = model.sample_size\n",
    "        sample_hr_dir, sample_lr_dir = results['output'] + 'valid_hr.png', results['output'] + 'valid_lr.png'\n",
    "\n",
    "        # Generated image save\n",
    "        iu.save_images(sample_x_hr,\n",
    "                       size=[1, 1],\n",
    "                       image_path=sample_hr_dir,\n",
    "                       inv_type='127')\n",
    "\n",
    "        iu.save_images(sample_x_lr,\n",
    "                       size=[1, 1],\n",
    "                       image_path=sample_lr_dir,\n",
    "                       inv_type='127')\n",
    "\n",
    "        learning_rate = 1e-4\n",
    "        for epoch in range(start_epoch, train_step['train_epochs']):\n",
    "            pointer = 0\n",
    "            for i in range(ds.n_images // train_step['batch_size']):\n",
    "                start = pointer\n",
    "                pointer += train_step['batch_size']\n",
    "\n",
    "                if pointer > ds.n_images:  # if 1 epoch is ended\n",
    "                    # Shuffle training DataSet\n",
    "                    perm = np.arange(ds.n_images)\n",
    "                    np.random.shuffle(perm)\n",
    "\n",
    "                    hr, lr = hr[perm], lr[perm]\n",
    "\n",
    "                    start = 0\n",
    "                    pointer = train_step['batch_size']\n",
    "\n",
    "                end = pointer\n",
    "\n",
    "                batch_x_hr, batch_x_lr = hr[start:end], lr[start:end]\n",
    "\n",
    "                # reshape\n",
    "                batch_x_hr = np.reshape(batch_x_hr, [train_step['batch_size']] + model.hr_image_shape[1:])\n",
    "                batch_x_lr = np.reshape(batch_x_lr, [train_step['batch_size']] + model.lr_image_shape[1:])\n",
    "\n",
    "                # Update Only G network\n",
    "                d_loss, g_loss, g_init_loss = 0., 0., 0.\n",
    "                if epoch <= train_step['init_epochs']:\n",
    "                    _, g_init_loss = s.run([model.g_init_op, model.g_cnt_loss],\n",
    "                                           feed_dict={\n",
    "                                               model.x_hr: batch_x_hr,\n",
    "                                               model.x_lr: batch_x_lr,\n",
    "                                               model.lr: learning_rate,\n",
    "                                           })\n",
    "                # Update G/D network\n",
    "                else:\n",
    "                    _, d_loss = s.run([model.d_op, model.d_loss],\n",
    "                                      feed_dict={\n",
    "                                          model.x_hr: batch_x_hr,\n",
    "                                          model.x_lr: batch_x_lr,\n",
    "                                          model.lr: learning_rate,\n",
    "                                      })\n",
    "\n",
    "                    _, g_loss = s.run([model.g_op, model.g_loss],\n",
    "                                      feed_dict={\n",
    "                                          model.x_hr: batch_x_hr,\n",
    "                                          model.x_lr: batch_x_lr,\n",
    "                                          model.lr: learning_rate,\n",
    "                                      })\n",
    "\n",
    "                if i % train_step['logging_interval'] == 0:\n",
    "                    # Print loss\n",
    "                    if epoch <= train_step['init_epochs']:\n",
    "                        print(\"[+] Epoch %04d Step %08d => \" % (epoch, global_step),\n",
    "                              \" MSE loss : {:.8f}\".format(g_init_loss))\n",
    "                    else:\n",
    "                        print(\"[+] Epoch %04d Step %08d => \" % (epoch, global_step),\n",
    "                              \" D loss : {:.8f}\".format(d_loss),\n",
    "                              \" G loss : {:.8f}\".format(g_loss))\n",
    "\n",
    "                        summary = s.run(model.merged,\n",
    "                                        feed_dict={\n",
    "                                            model.x_hr: batch_x_hr,\n",
    "                                            model.x_lr: batch_x_lr,\n",
    "                                            model.lr: learning_rate,\n",
    "                                        })\n",
    "\n",
    "                        # Summary saver\n",
    "                        model.writer.add_summary(summary, global_step)\n",
    "\n",
    "                    # Training G model with sample image and noise\n",
    "                    sample_x_lr = np.reshape(sample_x_lr, [model.sample_num] + model.lr_image_shape[1:])\n",
    "                    samples = s.run(model.g,\n",
    "                                    feed_dict={\n",
    "                                        model.x_lr: sample_x_lr,\n",
    "                                        model.lr: learning_rate,\n",
    "                                    })\n",
    "\n",
    "                    # Export image generated by model G\n",
    "                    # sample_image_height = model.output_height\n",
    "                    # sample_image_width = model.output_width\n",
    "                    sample_dir = results['output'] + 'train_{:08d}.png'.format(global_step)\n",
    "\n",
    "                    # Generated image save\n",
    "                    iu.save_images(samples,\n",
    "                                   size=[1, 1],\n",
    "                                   image_path=sample_dir,\n",
    "                                   inv_type='127')\n",
    "\n",
    "                    # Model save\n",
    "                    model.saver.save(s, results['model'], global_step)\n",
    "\n",
    "                # Learning Rate update\n",
    "                if epoch and epoch % model.lr_update_epoch == 0:\n",
    "                    learning_rate *= model.lr_decay_rate\n",
    "                    learning_rate = max(learning_rate, model.lr_low_boundary)\n",
    "\n",
    "                global_step += 1\n",
    "\n",
    "    end_time = time.time() - start_time  # Clocking end\n",
    "\n",
    "    # Elapsed time\n",
    "    print(\"[+] Elapsed time {:.8f}s\".format(end_time))\n",
    "\n",
    "    # Close tf.Session\n",
    "    s.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
