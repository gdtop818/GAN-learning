{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adward\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "import tfutil as t\n",
    "\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "\n",
    "# In image_utils, up/down_sampling\n",
    "def image_sampling(img, sampling_type='down'):\n",
    "    shape = img.get_shape()  # [batch, height, width, channels]\n",
    "\n",
    "    if sampling_type == 'down':\n",
    "        h = int(shape[1] // 2)\n",
    "        w = int(shape[2] // 2)\n",
    "    else:  # 'up'\n",
    "        h = int(shape[1] * 2)\n",
    "        w = int(shape[2] * 2)\n",
    "\n",
    "    return tf.image.resize_images(img, [h, w], tf.image.ResizeMethod.BILINEAR)\n",
    "\n",
    "\n",
    "class LAPGAN:\n",
    "\n",
    "    def __init__(self, s, batch_size=128, height=32, width=32, channel=3, n_classes=10,\n",
    "                 sample_num=10 * 10, sample_size=10,\n",
    "                 z_dim=128, gf_dim=64, df_dim=64, d_fc_unit=512, g_fc_unit=1024):\n",
    "\n",
    "        \"\"\"\n",
    "        # General Settings\n",
    "        :param s: TF Session\n",
    "        :param batch_size: training batch size, default 128\n",
    "        :param height: input image height, default 32\n",
    "        :param width: input image width, default 32\n",
    "        :param channel: input image channel, default 3 (RGB)\n",
    "        :param n_classes: the number of classes, default 10\n",
    "        - in case of CIFAR, image size is 32x32x3(HWC), classes are 10.\n",
    "        # Output Settings\n",
    "        :param sample_size: sample image size, default 8\n",
    "        :param sample_num: the number of sample images, default 64\n",
    "        # Model Settings\n",
    "        :param z_dim: z noise dimension, default 128\n",
    "        :param gf_dim: the number of generator filters, default 64\n",
    "        :param df_dim: the number of discriminator filters, default 64\n",
    "        :param d_fc_unit: the number of fully connected filters used at Disc, default 512\n",
    "        :param g_fc_unit: the number of fully connected filters used at Gen, default 1024\n",
    "        \"\"\"\n",
    "\n",
    "        self.s = s\n",
    "        self.batch_size = batch_size\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channel = channel\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.sample_size = sample_size\n",
    "        self.sample_num = sample_num\n",
    "\n",
    "        self.image_shape = [self.height, self.width, self.channel]\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.gf_dim = gf_dim\n",
    "        self.df_dim = df_dim\n",
    "        self.d_fc_unit = d_fc_unit\n",
    "        self.g_fc_unit = g_fc_unit\n",
    "\n",
    "        # Placeholders\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, self.n_classes],\n",
    "                                name='y-classes')  # one_hot\n",
    "        self.x1_fine = tf.placeholder(tf.float32, shape=[None, self.height, self.width, self.channel],\n",
    "                                      name='x-images')\n",
    "\n",
    "        self.x1_scaled = image_sampling(self.x1_fine, 'down')\n",
    "        self.x1_coarse = image_sampling(self.x1_scaled, 'up')\n",
    "        self.x1_diff = self.x1_fine - self.x1_coarse\n",
    "\n",
    "        self.x2_fine = self.x1_scaled  # [16, 16]\n",
    "        self.x2_scaled = image_sampling(self.x2_fine, 'down')\n",
    "        self.x2_coarse = image_sampling(self.x2_scaled, 'up')\n",
    "        self.x2_diff = self.x2_fine - self.x2_coarse\n",
    "\n",
    "        self.x3_fine = self.x2_scaled  # [8, 8]\n",
    "\n",
    "        self.z = []\n",
    "        self.z_noises = [32 * 32, 16 * 16, self.z_dim]\n",
    "        for i in range(3):\n",
    "            self.z.append(tf.placeholder(tf.float32,\n",
    "                                         shape=[None, self.z_noises[i]],\n",
    "                                         name='z-noise_{0}'.format(i)))\n",
    "\n",
    "        self.do_rate = tf.placeholder(tf.float32, None, name='do-rate')\n",
    "\n",
    "        self.g = []       # generators\n",
    "        self.g_loss = []  # generator losses\n",
    "\n",
    "        self.d_reals = []       # discriminator_real logits\n",
    "        self.d_fakes = []       # discriminator_fake logits\n",
    "        self.d_loss = []        # discriminator_real losses\n",
    "\n",
    "        # Training Options\n",
    "        self.d_op = []\n",
    "        self.g_op = []\n",
    "\n",
    "        self.beta1 = 0.5\n",
    "        self.beta2 = 0.9\n",
    "        self.lr = 8e-4\n",
    "\n",
    "        self.saver = None\n",
    "        self.merged = None\n",
    "        self.writer = None\n",
    "\n",
    "        self.bulid_lapgan()  # build LAPGAN model\n",
    "\n",
    "    def discriminator(self, x1, x2, y, scale=32, reuse=None):\n",
    "        \"\"\"\n",
    "        :param x1: image to discriminate\n",
    "        :param x2: down-up sampling-ed images\n",
    "        :param y: classes\n",
    "        :param scale: image size\n",
    "        :param reuse: variable re-use\n",
    "        :return: logits\n",
    "        \"\"\"\n",
    "\n",
    "        assert (scale % 8 == 0)  # 32, 16, 8\n",
    "\n",
    "        with tf.variable_scope('discriminator_{0}'.format(scale), reuse=reuse):\n",
    "            if scale == 8:\n",
    "                x1 = tf.reshape(x1, [-1, scale * scale * 3])  # tf.layers.flatten(x1)\n",
    "\n",
    "                h = tf.concat([x1, y], axis=1)\n",
    "\n",
    "                h = t.dense(h, self.d_fc_unit, name='disc-fc-1')\n",
    "                h = tf.nn.relu(h)\n",
    "                h = tf.layers.dropout(h, 0.5, name='disc-dropout-1')\n",
    "\n",
    "                h = t.dense(h, self.d_fc_unit // 2, name='d-fc-2')\n",
    "                h = tf.nn.relu(h)\n",
    "                h = tf.layers.dropout(h, 0.5, name='disc-dropout-2')\n",
    "\n",
    "                h = t.dense(h, 1, name='disc-fc-3')\n",
    "            else:\n",
    "                x = x1 + x2\n",
    "\n",
    "                y = t.dense(y, scale * scale, name='disc-fc-y')\n",
    "                y = tf.nn.relu(y)\n",
    "\n",
    "                y = tf.reshape(y, [-1, scale, scale, 1])\n",
    "\n",
    "                h = tf.concat([x, y], axis=3)  # (-1, scale, scale, channel + 1)\n",
    "\n",
    "                h = t.conv2d(h, self.df_dim * 1, 5, 1, pad='SAME', name='disc-conv2d-1')\n",
    "                h = tf.nn.relu(h)\n",
    "                h = tf.layers.dropout(h, 0.5, name='disc-dropout-1')\n",
    "\n",
    "                h = t.conv2d(h, self.df_dim * 1, 5, 1, pad='SAME', name='disc-conv2d-2')\n",
    "                h = tf.nn.relu(h)\n",
    "                h = tf.layers.dropout(h, 0.5, name='disc-dropout-2')\n",
    "\n",
    "                h = tf.layers.flatten(h)\n",
    "\n",
    "                h = t.dense(h, 1, name='disc-fc-2')\n",
    "\n",
    "            return h\n",
    "\n",
    "    def generator(self, x, y, z, scale=32, reuse=None, do_rate=0.5):\n",
    "        \"\"\"\n",
    "        :param x: images to fake\n",
    "        :param y: classes\n",
    "        :param z: noise\n",
    "        :param scale: image size\n",
    "        :param reuse: variable re-use\n",
    "        :param do_rate: dropout rate\n",
    "        :return: logits\n",
    "        \"\"\"\n",
    "\n",
    "        assert (scale % 8 == 0)  # 32, 16, 8\n",
    "\n",
    "        with tf.variable_scope('generator_{0}'.format(scale), reuse=reuse):\n",
    "            if scale == 8:\n",
    "                h = tf.concat([z, y], axis=1)\n",
    "\n",
    "                h = t.dense(h, self.g_fc_unit, name='gen-fc-1')\n",
    "                h = tf.nn.relu(h)\n",
    "                h = tf.layers.dropout(h, do_rate, name='gen-dropout-1')\n",
    "\n",
    "                h = t.dense(h, self.g_fc_unit, name='gen-fc-2')\n",
    "                h = tf.nn.relu(h)\n",
    "                h = tf.layers.dropout(h, do_rate, name='gen-dropout-2')\n",
    "\n",
    "                h = t.dense(h, self.channel * 8 * 8, name='gen-fc-3')\n",
    "\n",
    "                h = tf.reshape(h, [-1, 8, 8, self.channel])\n",
    "            else:\n",
    "                y = t.dense(y, scale * scale, name='gen-fc-y')\n",
    "\n",
    "                y = tf.reshape(y, [-1, scale, scale, 1])\n",
    "                z = tf.reshape(z, [-1, scale, scale, 1])\n",
    "\n",
    "                h = tf.concat([z, y, x], axis=3)  # concat into 5 dims\n",
    "\n",
    "                h = t.conv2d(h, self.gf_dim * 1, 5, 1, name='gen-deconv2d-1')\n",
    "                h = tf.nn.relu(h)\n",
    "\n",
    "                h = t.conv2d(h, self.gf_dim * 1, 5, 1, name='gen-deconv2d-2')\n",
    "                h = tf.nn.relu(h)\n",
    "\n",
    "                h = t.conv2d(h, self.channel, 5, 1, name='gen-conv2d-3')\n",
    "\n",
    "            h = tf.nn.tanh(h)\n",
    "\n",
    "            return h\n",
    "\n",
    "    def bulid_lapgan(self):\n",
    "        # Generator & Discriminator\n",
    "        g1 = self.generator(x=self.x1_coarse, y=self.y, z=self.z[0], scale=32, do_rate=self.do_rate)\n",
    "        d1_fake = self.discriminator(x1=g1, x2=self.x1_coarse, y=self.y, scale=32)\n",
    "        d1_real = self.discriminator(x1=self.x1_diff, x2=self.x1_coarse, y=self.y, scale=32, reuse=True)\n",
    "\n",
    "        g2 = self.generator(x=self.x2_coarse, y=self.y, z=self.z[1], scale=16, do_rate=self.do_rate)\n",
    "        d2_fake = self.discriminator(x1=g2, x2=self.x2_coarse, y=self.y, scale=16)\n",
    "        d2_real = self.discriminator(x1=self.x2_diff, x2=self.x2_coarse, y=self.y, scale=16, reuse=True)\n",
    "\n",
    "        g3 = self.generator(x=None, y=self.y, z=self.z[2], scale=8, do_rate=self.do_rate)\n",
    "        d3_fake = self.discriminator(x1=g3, x2=None, y=self.y, scale=8)\n",
    "        d3_real = self.discriminator(x1=self.x3_fine, x2=None, y=self.y, scale=8, reuse=True)\n",
    "\n",
    "        self.g = [g1, g2, g3]\n",
    "        self.d_reals = [d1_real, d2_real, d3_real]\n",
    "        self.d_fakes = [d1_fake, d2_fake, d3_fake]\n",
    "\n",
    "        # Losses\n",
    "        with tf.variable_scope('loss'):\n",
    "            for i in range(len(self.g)):\n",
    "                self.d_loss.append(t.sce_loss(self.d_reals[i], tf.ones_like(self.d_reals[i])) +\n",
    "                                   t.sce_loss(self.d_fakes[i], tf.zeros_like(self.d_fakes[i])))\n",
    "                self.g_loss.append(t.sce_loss(self.d_fakes[i], tf.ones_like(self.d_fakes[i])))\n",
    "\n",
    "        # Summary\n",
    "        for i in range(len(self.g)):\n",
    "            tf.summary.scalar('loss/d_loss_{0}'.format(i), self.d_loss[i])\n",
    "            tf.summary.scalar('loss/g_loss_{0}'.format(i), self.g_loss[i])\n",
    "\n",
    "        # Optimizer\n",
    "        t_vars = tf.trainable_variables()\n",
    "        for idx, i in enumerate([32, 16, 8]):\n",
    "            self.d_op.append(tf.train.AdamOptimizer(learning_rate=self.lr,\n",
    "                                                    beta1=self.beta1, beta2=self.beta2).\n",
    "                             minimize(loss=self.d_loss[idx],\n",
    "                                      var_list=[v for v in t_vars if v.name.startswith('discriminator_{0}'.format(i))]))\n",
    "            self.g_op.append(tf.train.AdamOptimizer(learning_rate=self.lr,\n",
    "                                                    beta1=self.beta1, beta2=self.beta2).\n",
    "                             minimize(loss=self.g_loss[idx],\n",
    "                                      var_list=[v for v in t_vars if v.name.startswith('generator_{0}'.format(i))]))\n",
    "\n",
    "        # Merge summary\n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "        # Model Saver\n",
    "        self.saver = tf.train.Saver(max_to_keep=1)\n",
    "        self.writer = tf.summary.FileWriter('./model/', self.s.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] No checkpoint file found\n",
      "[+] Epoch 000 Step 00000 =>   Avg D loss : 1.41298199  Avg G loss : 0.73700372\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-11d055702623>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-11d055702623>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;31m# classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# z-noises\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m                     })\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('../')\n",
    "import image_utils as iu\n",
    "from datasets import DataIterator\n",
    "from datasets import CiFarDataSet as DataSet\n",
    "\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "\n",
    "results = {\n",
    "    'output': './gen_img/',\n",
    "    'model': './model/LAPGAN-model.ckpt'\n",
    "}\n",
    "\n",
    "train_step = {\n",
    "    'epoch': 200,\n",
    "    'batch_size': 64,\n",
    "    'logging_interval': 1000,\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()  # Clocking start\n",
    "\n",
    "    # Training, test data set\n",
    "    ds = DataSet(height=32,\n",
    "                 width=32,\n",
    "                 channel=3,\n",
    "                 ds_path='C:/Users/adward//Desktop/GAN_learning/cifar-10-batches-py',\n",
    "                 ds_name='cifar-10')\n",
    "\n",
    "    ds_iter = DataIterator(ds.train_images, ds.train_labels,\n",
    "                           train_step['batch_size'])\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.Session(config=config) as s:\n",
    "        # LAPGAN model\n",
    "        model = LAPGAN(s, batch_size=train_step['batch_size'])\n",
    "\n",
    "        # Initializing variables\n",
    "        s.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Load model & Graph & Weights\n",
    "        saved_global_step = 0\n",
    "        ckpt = tf.train.get_checkpoint_state('./model/')\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            model.saver.restore(s, ckpt.model_checkpoint_path)\n",
    "\n",
    "            saved_global_step = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "            print(\"[+] global step : %s\" % saved_global_step, \" successfully loaded\")\n",
    "        else:\n",
    "            print('[-] No checkpoint file found')\n",
    "\n",
    "        sample_y = np.zeros(shape=[model.sample_num, model.n_classes])\n",
    "        for i in range(10):\n",
    "            sample_y[10 * i:10 * (i + 1), i] = 1\n",
    "\n",
    "        global_step = saved_global_step\n",
    "        start_epoch = global_step // (len(ds.train_images) // model.batch_size)  # recover n_epoch\n",
    "        ds_iter.pointer = saved_global_step % (len(ds.train_images) // model.batch_size)  # recover n_iter\n",
    "        for epoch in range(start_epoch, train_step['epoch']):\n",
    "            for batch_images, batch_labels in ds_iter.iterate():\n",
    "                batch_x = iu.transform(batch_images, inv_type='127')\n",
    "\n",
    "                z = []\n",
    "                for i in range(3):\n",
    "                    z.append(np.random.uniform(-1., 1., [train_step['batch_size'], model.z_noises[i]]))\n",
    "\n",
    "                # Update D/G networks\n",
    "                img_fake, img_coarse, d_loss_1, g_loss_1, \\\n",
    "                _, _, _, d_loss_2, g_loss_2, \\\n",
    "                _, _, d_loss_3, g_loss_3, \\\n",
    "                _, _, _, _, _, _ = s.run([\n",
    "                    model.g[0], model.x1_coarse, model.d_loss[0], model.g_loss[0],\n",
    "\n",
    "                    model.x2_fine, model.g[1], model.x2_coarse, model.d_loss[1], model.g_loss[1],\n",
    "\n",
    "                    model.x3_fine, model.g[2], model.d_loss[2], model.g_loss[2],\n",
    "\n",
    "                    model.d_op[0], model.g_op[0], model.d_op[1], model.g_op[1], model.d_op[2], model.g_op[2],\n",
    "                ],\n",
    "                    feed_dict={\n",
    "                        model.x1_fine: batch_x,  # images\n",
    "                        model.y: batch_labels,   # classes\n",
    "                        model.z[0]: z[0], model.z[1]: z[1], model.z[2]: z[2],  # z-noises\n",
    "                        model.do_rate: 0.5,\n",
    "                    })\n",
    "\n",
    "                # Logging\n",
    "                if global_step % train_step['logging_interval'] == 0:\n",
    "                    batch_x = ds.test_images[np.random.randint(0, len(ds.test_images), model.sample_num)]\n",
    "                    batch_x = iu.transform(batch_x, inv_type='127')\n",
    "\n",
    "                    z = []\n",
    "                    for i in range(3):\n",
    "                        z.append(np.random.uniform(-1., 1., [model.sample_num, model.z_noises[i]]))\n",
    "\n",
    "                    # Update D/G networks\n",
    "                    img_fake, img_coarse, d_loss_1, g_loss_1, \\\n",
    "                    _, _, _, d_loss_2, g_loss_2, \\\n",
    "                    _, _, d_loss_3, g_loss_3, \\\n",
    "                    _, _, _, _, _, _, summary = s.run([\n",
    "                        model.g[0], model.x1_coarse, model.d_loss[0], model.g_loss[0],\n",
    "\n",
    "                        model.x2_fine, model.g[1], model.x2_coarse, model.d_loss[1], model.g_loss[1],\n",
    "\n",
    "                        model.x3_fine, model.g[2], model.d_loss[2], model.g_loss[2],\n",
    "\n",
    "                        model.d_op[0], model.g_op[0], model.d_op[1], model.g_op[1], model.d_op[2], model.g_op[2],\n",
    "\n",
    "                        model.merged,\n",
    "                    ],\n",
    "                        feed_dict={\n",
    "                            model.x1_fine: batch_x,  # images\n",
    "                            model.y: sample_y,       # classes\n",
    "                            model.z[0]: z[0], model.z[1]: z[1], model.z[2]: z[2],  # z-noises\n",
    "                            model.do_rate: 0.,\n",
    "                        })\n",
    "\n",
    "                    # Print loss\n",
    "                    d_loss = (d_loss_1 + d_loss_2 + d_loss_3) / 3.\n",
    "                    g_loss = (g_loss_1 + g_loss_2 + g_loss_3) / 3.\n",
    "                    print(\"[+] Epoch %03d Step %05d => \" % (epoch, global_step),\n",
    "                          \" Avg D loss : {:.8f}\".format(d_loss),\n",
    "                          \" Avg G loss : {:.8f}\".format(g_loss))\n",
    "\n",
    "                    # Training G model with sample image and noise\n",
    "                    samples = img_fake + img_coarse\n",
    "\n",
    "                    # Summary saver\n",
    "                    model.writer.add_summary(summary, global_step)  # time saving\n",
    "\n",
    "                    # Export image generated by model G\n",
    "                    sample_image_height = model.sample_size\n",
    "                    sample_image_width = model.sample_size\n",
    "                    sample_dir = results['output'] + 'train_{0}.png'.format(global_step)\n",
    "\n",
    "                    # Generated image save\n",
    "                    iu.save_images(samples, size=[sample_image_height, sample_image_width],\n",
    "                                   image_path=sample_dir,\n",
    "                                   inv_type='127')\n",
    "\n",
    "                    # Model save\n",
    "                    model.saver.save(s, results['model'], global_step)\n",
    "\n",
    "                global_step += 1\n",
    "\n",
    "        end_time = time.time() - start_time  # Clocking end\n",
    "\n",
    "        # Elapsed time\n",
    "        print(\"[+] Elapsed time {:.8f}s\".format(end_time))\n",
    "\n",
    "        # Close tf.Session\n",
    "        s.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
